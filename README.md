# Linguifeye
H.A.R.D. Hack 2018 Project

## Table of Contents
- [Team Members](https://github.com/eminguyen/hardhack2018#team-members)
- [Purpose and Idea](https://github.com/eminguyen/hardhack2018#purpose-and-idea)
- [Parts](https://github.com/eminguyen/hardhack2018#parts)
- [Build Guide](https://github.com/eminguyen/hardhack2018#build-guide)
- [Demonstration](https://github.com/eminguyen/hardhack2018#demonstration)
- [Additional Credit](https://github.com/eminguyen/hardhack2018#additional-credit)
- [Special Thanks](https://github.com/eminguyen/hardhack2018#special-thanks)

## Team Members
- [Anish Sinha](https://github.com/Anish-Sinha)
- [Akhil Birlangi](https://github.com/oriany)
- [Antony Nguyen](https://github.com/eminguyen)
- [Chengzhu Duan](https://github.com/c3duan)
- [Jacinth Gudetti](https://github.com/Injun86) 

## Purpose and Idea
Part of making the society a better place is to help the disabled. Many members of the society are visually impaired, and this disability made their everyday life a huge struggle. With the goal of making people’s life better with modern technology, our idea is to provide blind people with an “eye” that allows them to know their surroundings without physically seeing it. People with visual impairment are extremely vulnerable in public, their inability to see prevents them from seeing important signals and vital street signs. These vital signs lack a way of communication for those who are visually impaired. For example, street signs cannot have braille. The inspiration comes from the hope of giving visually impaired people the opportunity of travel. We decided to approach this project with a different perspective: attaching a camera that can identify text of any language and read it out loud from images and videos taken in real time. To make this project more useful, we also added a translation feature that is able to translate the seen texts to any language the user wanted. This enables blind people to not only go out of their home, but to also travel around the world.

## Parts
1. DragonBoard 410C
2. Audio Mezzanine
3. Monitor, Computer Peripherals
4. USB Hub
5. Webcam
6. Speaker

## Build Guide
1. Setup DragonBoard and install python 3.
2. Get pip
3. Install googletrans and gTTS through pip
4. Download Python OCR file from Dan Nguyen’s GitHub.
5. Once libraries are set up, download Linguifye from https://github.com/eminguyen/hardhack2018
6. Languages can be changed internally within the translate_xx.py files by altering the two letter language codes.


## Demonstration
[Link to video demonstration](https://drive.google.com/file/d/1afC0O9u-6lPfeLEaSp877QxH6qph6j-v/view?usp=sharing)

## Additional Credit
- [Dan Nguyen's Google Cloud Vision scanner](https://gist.github.com/dannguyen/a0b69c84ebc00c54c94d)
- [Pierre Nicolas Durette's gTTS interface](https://pypi.python.org/pypi/gTTS)
- [SuHun Han's Googletrans library](https://pypi.python.org/pypi/googletrans)

## Special Thanks
- [Qualcomm](qualcomm.com)
- [Linaro](https://www.linaro.org/)
- [UCSD ECE Department](http://www.ece.ucsd.edu/)
- [IEEE San Diego](https://www.facebook.com/ieeeucsd/)
- [Eta Kappa Nu](https://www.facebook.com/hknucsd/)